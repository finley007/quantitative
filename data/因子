传统量价类因子：
威廉因子：
（当前价格 - 前一千个最低价格）/（前一千个最高价格 - 前一千个最低价格）
问题：
1. 是否渐变时间窗？


现货类因子
总委比（前10）
 总委买金额/（总委买金额+总委卖金额）
 总委卖金额 = 叫卖总量 * 加权平均叫卖价
 总委买金额 = 叫买总量 * 加权平均叫买价

总成交量

/*
分红股的收益率均值减去非分红股的收益率均值
大市值收益率均值减去小市值收益率的均值
高成长股的收益率的均值减去低成长股的收益率的均值
*/



截面因子
价差因子：

期现因子


算法：
1. 对单一产品，在主力合约切换日进行拼接，如果某些因子值依赖于之前的交易日的数据则切换到对应的合约计算。之后多个商品再拼接。
|-------------------|---|
                |---|-----------------------|
                  切换日
因子文件结构：
datetime factor1 factor2.... ret1 ret2...
a. 按品种生成因子文件
遍历品种，遍历合约，读取股指k线，如果因子可以完全由股指k线计算则直接按合约计算因子值，拼接的时候考虑主力合约。
如果需要股指或者股票tick数据则加载对应的文件在内存中关联，计算因子值。为了提高计算效率需要对列进行过滤，只用到有用的列，特别是股票的tick数据    
b. 合并因子文件

2. 现货类因子场景分类
现货类因子因为要结合现货数据所以对股指k线在一个时间点上有一对多的关系：

--------------->时间
股指k线---------------- 股票现货 +++++++++++++++++++++++++  | 股票
                                 +++++++++++++++++++++++++  |
                                ++++++++++++++++++++++++++  |
                                                            |
                                                           \|/
四种场景：
a. 截面：因子计算只依赖于单一的时间点，可以直接作groupby
b. 矩阵：因子计算依赖于一段时间，因此在时间轴和股票轴是一个矩阵，这类因子先在时间轴对单个股票进行计算，再在股票轴做合并。需要做跨天处理？-需要扩展到多天的情形
时间轴维度的计算针对单一stock，在enrich_stock_data内实现，如果需要跨天，实现一个缓存，缓存对应天的数据，实现懒加载模式，如果缓存没有命中则重新加载文件。
c. 竞价：这类因子有可能是截面也有可能是矩阵，主要在集合竞价时间段内计算。
d. 衍生因子，基于前三类因子值做差分，累加或者变化率
获取原始因子文件
按合约获取天

3. 现货数据缓存框架
要经常获取现货数据进行计算，用一个专门的数据结构作为现货数据提取接口。
接口实现采用缓存，缓存用已有的第三方缓存框架。

4. 现货因子框架优化
调用栈：IF-1810 基准
  caculate - 601.32268140 s - 进程并行，保存临时文件
 159  - get_stock_tick_data - 9.11405760 s - io操作，线程并行，线程并行提升不明显，主要因为加载文件用时比较小
        850 - access - 0.00885280 s 
            - enrich_stock_data
      - caculate_implement
      - merge_with_stock_data - 0.03861950 s
a. 调整代码结构，处理停盘数据 598.02285550 s
b. 多线程加载数据，10并发 575.69867400 s
c. 多线程加载数据，20并发 579.12618640 s
d. 多进程加载数据，10并发 588.22073370 s
合并数据文件，增加io时间来提高多线程的性能
  测试文件加载时间：
    1个合约文件，200m，
      小文件串行：7.63308210 s
      小文件多线程（5并发）： 5.43745490 s
      小文件多进程（10并发）： 5.21482470 s
      大文件串行： 7.93063650 s
    8个合约文件，每个文件200m，
      小文件串行：58.60950070 s
      小文件多线程（5并发）： 45.97187390 s
      小文件多进程（10并发）： 39.73711160 s
      大文件串行： 68.75293950 s
      大文件多线程（5并发）： 54.61778720 s
      大文件多进程（2并发）：73.20560230 s
  这个测试不太理想，但是因为是纯加载文件，没有考虑到和计算逻辑的并行化：
  找到IF-1810相关的交易日，生成这些天对应的合并文件：  2018-08-20 - 2018-10-19
e. 大文件串行，1788.12906180 s
f. 大文件直接返回 1454.29969490 s
print全局开关
g. 测试 636.77423870 s
按天操作的进程并行
  直接汇总（可能有内存问题）
h. 分页 165.37310220 s
  或者存储中间结果
factor_caculate级别并行化
  按股指的的思路分成两步：
  1. 因子按合约计算中间结果，保存为临时文件
  2. 拼接临时文件
10个合约：'IF1810','IF1811','IF1812','IF1901','IF1902','IF1903','IF1904','IF1905','IF1906','IF1907'
g. 串行执行：3375.20317620 s
AssertionError: daemonic processes are not allowed to have children
h. 并行执行3 * 6：2965.52812560 s
   并行执行2 * 10：2894.79140340 s
   并行执行3 * 8: oom

5. 现货因子断点续传
增加因子处理表，每一行代表一个合约
每一个分页保存一次临时数据
每一次执行先检查因子处理表，读取断点位置，从断点页开始执行

6.因子计算原则：
a. rolling会导致rolling周期长度的数据为空，解决方法：
如果是mean，可以滑动时间窗
如果是其它比如计算回归或者其它复杂运算必须要求确定长度则填0
b. 数据缺失解决方法
按天缺失全部股票数据，直接删除
按天缺失部分股票数据（如停盘），正常进行聚合运算
缺失部分时刻数据，想办法修复
分因子缺失部分字段数据参考a


因子测试框架：
逻辑测试：
1. 测试算子
测试方法：
  逻辑 单元测试
  对比 RSI OBV ADX
  人工比较
2. 测试因子
测试方法：
  按合约和天生成片段文件，人工比对：caculate_manually_check
  对于现货因子过滤股票

因子修复框架：
两种方案：
1. 如果大面积数据有问题，比如因为计算方法导致的就重新生成，若是某几天的有问题，只重新生成这几天的然后替换，方法：fix_factor
2. 如果只是少数数据有问题则在原始因子文件上修复，可以单独写一个handler
参数：因子，品种，日期列表（可为空），修复接口
框架也用和股票数据类似的方法
这里给出两个修复因子的例子：
a. 在分析因子稳定性发现会有一些极值，最终分析导致这些极值的原因是因为股票数据有很多10档委买委卖数据都是0（因子问题finley-20230309），修复方法：
   做一次股票数据检查找出有问题的股票数据
   做默认修复，把出问题的数据在股指成分表中的状态按date+stock标记为不可用状态2
   对这些天调用fix_factor重新计算
b. 部分10档委买委卖数据找到了新的数据源,可以修复(针对a的问题做2次修复)
   将已修复的20230309-finley重新标记为1，针对大于4000条错误记录的查询重新执行修复，修复的同时将股指成分表中的状态重新改回0
   根据20230309-finley状态为2的记录做查询，调用fix_factor重新计算



因子分析框架：
基本分析
  合约数，天数，记录数（盘前，早盘，午盘），为空或者0的记录数
统计分析
平稳性分析
1. 按日计算均值和方差并绘制折线图，生成统计信息
2. 平稳时间序列分析

因子处理和合并框架
生成到一个新目录下


性能测试
参数调优
1. 因子单合约执行记录
   生成报告文件：
   路径：E:\data\report\factor\performance
   文件格式：csv
   文件名：合约_合约日期范围_时间_single_instrument_performance.csv
   列名：分类编码 分类名称 因子编码 因子版本 因子参数 执行时间


问题：
1. 跨合约处理: 见算法1
2. 现货类因子问题
跨天的连续性处理
2022年缺失
给出写现货因子的思路


